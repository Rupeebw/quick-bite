# Github reference for respective code
https://github.com/rupeshpanwar/k8s-simple-deployment

# Why & What
<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126955029-94dffe3b-3bfc-43bb-a563-766d5a2b0ebb.png">
<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126957345-32131eb9-47e0-4614-a4f6-8ef47355198d.png">

<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126955087-dda079ba-34c2-439f-beb2-09815d0893d0.png">

<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126955328-f4767611-166f-4bfb-b9fd-ce0465d16bbd.png">

<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126955402-66889213-9247-4852-a70b-05b0119f3936.png">
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126981495-9004a943-8c9a-4d36-9f6c-2202ce48e0c5.png">

## using kubernetes
<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126955775-a2e82a3f-b849-4146-bedf-d485e16ff913.png">
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126981919-c03dc38f-5889-4fd0-af33-1fa1b26e3dd3.png">
- kubectl way 
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126982151-fc1f4d48-081b-446f-9bc4-d43d4a6799c9.png">
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126982359-212a4c43-0ff5-451d-9006-f87d9856c6b3.png">

- manifest file (yml) way
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126982557-d3c6a2e3-36c8-4672-82a7-407d9c85a148.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126982795-56f1c512-4486-4bfc-9e92-121e6ce58c52.png">


# K8S in dev / prod
<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126957588-e3c23e6d-0a05-4c0b-a525-2d0bea2e006e.png">

<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126958039-61cd4beb-c8cf-49fe-b952-37e878721d51.png">

<img width="1189" alt="image" src="https://user-images.githubusercontent.com/75510135/126958302-63f3a8e1-8b80-406d-92bf-4cdf173acc61.png">

## some insight about container n deployment approach
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126971469-8170a2ff-ea4a-43c7-ae38-ce00e15efad9.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126971701-54131a43-ae43-4d25-83f1-525d1c277757.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126972465-d82240f9-653b-462e-92f1-3fb04354fb53.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126972606-2b31171c-d967-42ad-9adf-3b71e626c5ea.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126973211-8963b033-7b65-4bd9-94ea-3f43ea5be8c8.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126974237-8f9a9725-6a8a-4193-ae8a-adc19808d9a8.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126974330-8e824e5f-c4f3-4a2e-b057-8b17183a3574.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126974616-3d46a701-b0ad-416c-865d-5a8d37379ecf.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126974916-ebbfbd77-0276-468e-ba78-dfc811002ffc.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126975706-9afc8b80-0665-4d2f-815c-d8520ac7f144.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126976075-48b768e0-d0ab-482f-9357-99cf4be401fd.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126976384-0e542b51-41be-4022-aadb-ff2fc1936d2a.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126979856-028f55a7-289c-4fc9-8ce5-ab319421a0db.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126980083-877d1fb4-35c0-4714-9057-17610cb04131.png">
<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126980427-cd6ed8f8-4429-4c86-a425-9085271ec281.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126980679-e0d3ec9f-d78e-406c-850c-908e66496a1e.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126980716-eb962dcc-60ab-49df-ad88-2adf5feb3692.png">

<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126984905-c28b727d-8ce8-43a3-bfda-5646611b4618.png">
- limitation in pod config changes

<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126986357-99a2dce2-0b11-4ecb-a288-5dcc674d7c4e.png">

<img width="1076" alt="image" src="https://user-images.githubusercontent.com/75510135/126990647-6b91afe3-af85-49db-8236-8870406ec6e8.png">

- possible change via Deployment

<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126986450-b3bf80e3-08da-4b44-8404-52ee59b5ec8d.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126999219-cd57dcdd-d997-4683-a4e2-b42c455ed9fc.png">

<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126999366-525ea9e2-47ef-4ab8-bec6-f8825e28e616.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126999576-26c4cfea-3e68-459e-a7b7-3a38ee922a03.png">
## Cluster IP
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127093203-e9452ff7-5e61-4170-ba66-f2e547a952e4.png">
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127093351-dd728dbe-5174-4165-8809-c8a896c2f417.png">

<img width="883" alt="image" src="https://user-images.githubusercontent.com/75510135/127094665-3647a822-5b9b-410b-9bbb-3a0454826d6b.png">


# Deployment - way to maintain sets of containers(RC)
<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126983239-ed456610-9cda-4992-bbe8-a8ea1bd897dd.png">
<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126986777-bf6aba37-54ac-46a8-8656-75f6bd4c62ae.png">
<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126987079-868925d8-4646-40d2-bc4b-27d589c23844.png">
<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126987130-688fe329-13e0-4c56-bd19-e5393c76c36a.png">
<img width="883" alt="image" src="https://user-images.githubusercontent.com/75510135/126988274-ae314c4c-2843-4038-a2bb-ca05a0105592.png">
<img width="1076" alt="image" src="https://user-images.githubusercontent.com/75510135/126988755-a0e9c2d9-71d5-42df-a72e-e3d86b1bab95.png">

- service to expose the pod

<img width="1076" alt="image" src="https://user-images.githubusercontent.com/75510135/126991928-1ce77765-e309-4ffd-a6dd-d6a0f7b55c31.png">
<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/126992368-03585794-44e7-4f4d-aa24-c2035e6d27e8.png">

- update a deployment

<img width="1076" alt="image" src="https://user-images.githubusercontent.com/75510135/126994216-a31fccb2-b8bb-4d17-b0cc-86fa3cb475db.png">

- problem in deploying the update via deployment(refering :latest image)

<img width="1032" alt="image" src="https://user-images.githubusercontent.com/75510135/126995727-469a7512-0b5f-4b41-ae7e-c8c51e06bd0f.png">
- Solutions

<img width="1076" alt="image" src="https://user-images.githubusercontent.com/75510135/126997851-9ad3f157-0dde-4442-980e-8fa28d0094fd.png">

- update deployment using Imperative way

<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126998508-881e35ce-8af1-4300-bcbe-2065e32be3c3.png">

<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126998774-ebdb4f8e-6991-4387-b5ea-32392675ae8e.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126999196-f8f49cbb-122b-4fc1-96b5-7731159f8810.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126999381-1ecc43e0-9f39-4a24-a577-b5fad0dd6c4a.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/126999555-f396cbd3-fb8a-4eaf-9cd0-0be61dcb644a.png">

## Volume
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127110887-53c26530-e890-4a1f-911d-4455b46e8489.png">
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127110940-d8292dba-2d13-45ce-8f2a-5176b52c4d50.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127111034-1e383752-1bad-4860-8826-8df2722f1955.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127111243-6ac4ecb1-0d95-43da-8f60-fda48f634d1a.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127111339-32865975-3a82-4a75-8094-f5ee654cdeb5.png">
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127112707-3e0d20a3-e5ce-410f-9a3e-6fa2ae8b0cff.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127112842-fd882960-78e8-4a57-b0a3-f9394fd5362a.png">

- Note , in K8S, Volumne is tied with POD , if pod is deleted then Volumne also gets deleted
- Volumne Vss Persistent Volumne

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127113628-ec8d3787-271b-4f5f-8497-bed0057a7100.png">

- analogy

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127114466-71d4e250-8098-45ba-b34b-9981267d554d.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127115985-aef40652-dfc4-4fc4-8b3b-c3ca87c3f270.png">
<img width="883" alt="image" src="https://user-images.githubusercontent.com/75510135/127116872-c1258565-b8cb-462f-832a-41b9d54de256.png">
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127117336-ffa465aa-9b2a-4b6c-b9f2-6defe5e1daac.png">
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127118054-b999832c-e6e5-4e30-92b8-24c7015d9738.png">
- kubectl get storageclass
- kubectl describe storageclass

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127118999-5276856c-72f6-4912-8dd9-c50729c95fcd.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127119853-14def25c-358e-42a0-ad3c-1aa57b016e76.png">


- to get the advertised volumne 
-<img width="683" alt="image" src="https://user-images.githubusercontent.com/75510135/127134929-6589b628-f29a-4240-bd65-8b8a702f49a0.png">

- kubectl get pv

- kubectl get pvc
- setup Env to connect to DB

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127137904-6605adab-7efb-44b7-a11c-7159a645664a.png">

- via cluster IP service

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127138043-e05d8af0-bcc3-4425-8899-38605b28a70b.png">

- for worker

<img width="683" alt="image" src="https://user-images.githubusercontent.com/75510135/127139004-2ab8618d-1392-47bf-813d-9ffc8d3e330d.png">

- for server

<img width="683" alt="image" src="https://user-images.githubusercontent.com/75510135/127139689-0a63ed8d-89d1-4f5d-ac23-f2b0511c4d20.png">

- Secret

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127139947-9f303a77-920f-4fda-b436-bc40e03f3b10.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127140354-62b772ab-36bf-43b4-b96c-bb2370a8e789.png">
- type of secret, generic/docker-registery / TLS
<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/127141584-c1b78b13-9013-4214-bae6-bb03532bd218.png">


- eg: update postgres password in server deployment

<img width="683" alt="image" src="https://user-images.githubusercontent.com/75510135/127142625-28d59e40-b3d8-4c5e-b857-0863a6714695.png">

- eg: update postgres password in postgres deployment

<img width="696" alt="image" src="https://user-images.githubusercontent.com/75510135/127144621-2e33bcda-33e2-45d0-ae99-5fc2886ef02c.png">


# Networking
<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127164395-cabf5c55-5917-4f9d-85f2-f87010464b93.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127164920-669367c4-1065-4080-a92f-d1ccff00240e.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127165402-4ac7437e-94cf-420f-ba8d-8cdf52fb7f8f.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127165858-f8197e6c-373a-4646-b5b9-84e9b3bf4e27.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127166194-fc3871de-aed6-4c0c-8465-b68ffeb040b7.png">

<img width="1133" alt="image" src="https://user-images.githubusercontent.com/75510135/127166354-707e3a70-502f-41ab-b47a-5347f921e486.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127166951-0a233297-b6dc-4c68-9e46-62b500c738aa.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127167128-88aa62fe-68b8-495e-b97c-f7855b74f69c.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127167366-3fa266c7-4255-4939-b6fd-c3e7d94d0116.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127167586-ea74c0ed-24fd-4923-a901-bf53e126fe89.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127167778-334da7c8-5175-4bb9-8f2b-43c5677fd97c.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127167948-2bcdc636-8a01-4122-b15a-3c8cf260fd5f.png">

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127168324-48a30b18-194b-444b-84d0-ab0ced4cefb8.png">

- why notusing  Normal NGiNX

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127168914-7463f451-08ba-458d-8cd7-6c3feb7036e8.png">

- normal NgInx, bypass clusterIP service and directly connect to POD

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127169541-f2a78527-a260-4cf3-8be9-2900677cc61c.png">

- Reference , https://www.joyfulbikeshedding.com/blog/2018-03-26-studying-the-kubernetes-ingress-system.html. 
- Ingress Nginx Mandatory Commands
- https://kubernetes.github.io/ingress-nginx/deploy/#provider-specific-steps
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.48.1/deploy/static/provider/cloud/deploy.yaml

<img width="1039" alt="image" src="https://user-images.githubusercontent.com/75510135/127172372-32ebdc59-e488-448f-8c25-a5342d121c14.png">
- verify installation

kubectl get pods -n ingress-nginx \
  -l app.kubernetes.io/name=ingress-nginx --watch
  
<img width="696" alt="image" src="https://user-images.githubusercontent.com/75510135/127200392-a03ead26-d95c-4128-bff3-0ce0a077f3ee.png">


# Docker Engagement
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/127074215-9345394b-656a-499e-bdf7-db284439de38.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/127074348-24572c7b-16ef-4eff-8c62-564eaff603e5.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/127074556-920d6f49-2f23-4ede-9f41-3d599e72cc08.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/127074780-aa1dcc64-e4ac-4450-a21f-e54676ebcb1c.png">
<img width="990" alt="image" src="https://user-images.githubusercontent.com/75510135/127075008-33b7ab61-0c07-470d-8962-755b1cb74e79.png">

# Docker Desktop's Kubernetes Setup and Installation - macOS

2-22-2021

These instructions are for using Docker Desktop's built-in Kubernetes instead of Minikube on macOS. If Docker Desktop is not supported on your OS, or, you wish to use Minikube, please see the instructions for installing and configuring Minikube here.

Note - It is assumed that Docker Desktop has already been installed and is in a working state.

    Click the Docker icon found on the right side of the macOS menu bar.

    Click Preferences from the dropdown menu that appears.

    Click Kubernetes in the left side menu.

    Check the Enable Kubernetes box and then click the Apply & Restart button.

    Click Install to allow the cluster installation.

    After the installation dialog disappears, click the Docker icon to make sure there is a Kubernetes is running message and green circle.

    Then, select Kubernetes in this dropdown menu and make sure the context is set to docker-desktop and not something else like minikube or kind.

    Finally, open up your terminal and make sure that you can run kubectl version

Note - the client and server can be off by one minor version without error or issue.
Usage


Going forward, any minikube commands run in the lecture videos can be ignored. Also, you will be using localhost to access the services running in your cluster instead of the minikube IP address.

For example, in the first project where we deploy our simple React app, using minikube we would visit:

192.168.99.101:31515

Instead, when using Docker Desktop's Kubernetes, we would visit: localhost:31515

# Docker Desktop's Kubernetes Setup and Installation - Windows

2-22-2021

These instructions are for using Docker Desktop's built-in Kubernetes instead of Minikube on Windows. If you do not wish to use Docker Desktop, please see the instructions for installing and configuring Minikube here.

Note - It is assumed that Docker Desktop has already been installed and is in a working state.

    Click the upward-facing arrow on the right side of the Windows System Tray, then click the Docker icon.

    Click the Gear icon in the top menu bar of the Docker Desktop application.

    In the General settings section, make sure that the Use WSL 2 based engine box is checked. This assumes that WSL2 is supported by your OS and has already been installed and enabled. If not, please see the WSL2 setup instructions here.

    Click Kubernetes in the left side menu.

    Check the Enable Kubernetes box and then click the Apply & Restart button.

    Click Install to allow the cluster installation.

    After the installation dialog disappears, look at the bottom left side of the General Settings page and make sure there is a green Kubernetes icon. If you click it, it should display a RUNNING tooltip.

    Finally, open up your terminal of choice and make sure that you can run kubectl version

    Note - the client and server can be off by one minor version without error or issue.

Usage


Going forward, any minikube commands run in the lecture videos can be ignored. Also, you will be using localhost to access the services running in your cluster instead of the minikube IP address.

For example, in the first project where we deploy our simple React app, using minikube we would visit:

192.168.99.101:31515

Instead, when using Docker Desktop's Kubernetes, we would visit: localhost:31515

# Updated Minikube Install and Setup Info - macOS

2-22-2021

In the upcoming lecture, we will set up and install Minikube using Homebrew. The installation instructions have changed slightly. If you are already using Docker Desktop's Kubernetes, you do not need Minikube and these instructions can be skipped.
Install Minikube with Homebrew


First, make sure you have Homebrew installed. If not, follow the instructions here:

https://brew.sh/

Then, in your terminal, run:

brew install minikube

Your output should look something like this (it will be ok if it is not exact)
Install Minikube Directly


If you do not wish to use Homebrew, you can use cURL to download the binaries.

In your terminal, run:

curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64

sudo install minikube-darwin-amd64 /usr/local/bin/minikube

Your output should look something like this:
Starting Minikube and Testing Installation


After you have successfully installed Minikube we need to start and test the cluster to make sure everything is working correctly.

1. Start with VM driver:

In your terminal, run:

minikube start --driver=hyperkit

Your output should look similar to this:

Note - It is very important to use a vm driver like hyperkit. If you do not pass a driver flag to the start command Minikube will use the docker driver instead. This will not match what is shown in the course and will not work with an ingress (used later).

https://minikube.sigs.k8s.io/docs/drivers/docker/#known-issues

2. Check Minikube Status

After you see a Done! message in your terminal, run minikube status to make sure the cluster is healthy. Pay particular attention that the apiserver is in a "Running" state.

3. Check kubectl

Lastly, open up your terminal and make sure that you can run kubectl version

Note - the client and server can be off by one minor version without error or issue.

<img width="1030" alt="image" src="https://user-images.githubusercontent.com/75510135/126958884-6a15248a-67a6-4263-bc32-7f61a1585b01.png">

# Minikube Setup on Windows

2-22-2021

These instructions are for setting up and installing Minikube for use on Windows. If you are already using Docker Desktop's Kubernetes, you do not need Minikube and these instructions can be skipped.
Install Minikube


1. Download the Windows installer here:

https://storage.googleapis.com/minikube/releases/latest/minikube-installer.exe

2. Double click the .exe file that was downloaded and run the installer. All default selections are appropriate.
Starting Minikube (requires HyperV)


After you have successfully installed Minikube we need to start and test the cluster to make sure everything is working correctly.

1. Start with VM driver:

In your terminal, run:

minikube start --driver=hyperv

Your output should look similar to this:

Note - It is very important to use a vm driver like hyperv. If you do not pass a driver flag to the start command Minikube will use the docker driver instead. This will not match what is shown in the course and will not work with an ingress (used later).

https://minikube.sigs.k8s.io/docs/drivers/docker/#known-issues

2. Check Minikube Status

After you see a Done! message in your terminal, run minikube status to make sure the cluster is healthy. Pay particular attention that the apiserver is in a "Running" state.

3. Check kubectl

Lastly, open up your terminal and make sure that you can run kubectl version

Note - the client and server can be off by one minor version without error or issue.

# Minikube Setup on Linux

These instructions should be valid for Debian, Ubuntu, or Mint Linux distributions. Your experience may vary if using other distributions such as RHEL, Arch, non-desktop distributions like Ubuntu server, or lightweight distros which may omit many expected tools.
Install Minikube


In your terminal run the following:

curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

sudo install minikube-linux-amd64 /usr/local/bin/minikube
Starting Minikube and Testing Installation


After you have successfully installed Minikube we need to start and test the cluster to make sure everything is working correctly.

1. Add your user to the docker group

Note - If this step was performed when Docker was installed, it can be skipped.

In your terminal, run:

sudo usermod -aG docker $USER && newgrp docker

Log out of the user profile and log back in so these changes take effect. If running inside a VM, you will need to restart the entire machine, not just log out.

2. Start with the default driver:

In your terminal, run:

minikube start

Your output should look similar to this:

2. Check Minikube Status

After you see a Done! message in your terminal, run minikube status to make sure the cluster is healthy. Pay particular attention that the apiserver is in a "Running" state.

3. Install kubectl

In your terminal run the following:

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

4. Test kubectl

Lastly, open up your terminal and make sure that you can run kubectl version

Note - the client and server can be off by one minor version without error or issue.


# Goal
<img width="1030" alt="image" src="https://user-images.githubusercontent.com/75510135/126960186-108d68eb-a4ad-4fc6-b556-e2f6b1c56936.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126960499-c68680bc-bc78-42bd-9301-2fc8ddd854f4.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126960525-f28a408e-2067-42c4-9f30-f0b67f4bd0bd.png">

<img width="1077" alt="image" src="https://user-images.githubusercontent.com/75510135/126961198-6e6fbdbf-3c18-4998-a3d2-018a0e25695f.png">

# Create Pod definition for client(react app)
<img width="883" alt="image" src="https://user-images.githubusercontent.com/75510135/126970020-5e19fcfb-a822-4296-8c72-a7d77e146d09.png">

```
apiVersion: v1
kind: Pod
metadata:
  name: client-pod
  labels:
    name: web
spec:
  containers:
  - name: client
    image: rupeshpanwar/multi-client
    resources:
      limits:
        memory: "128Mi"
        cpu: "500m"
    ports:
      - containerPort: 3000
  ```
  # Create Node port service client-node-port.yaml
  ```
apiVersion: v1
kind: Service
metadata:
  name: client-node-port
spec:
  type: NodePort
  selector:
    app: web
  ports:
  - port: 3050
    targetPort: 3000
    nodePort: 31515


```

## apply above config to create pod n service

<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/126977594-bf271ea9-9de2-4d8e-b65b-a02e8ba017ae.png">

<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/126978703-20c4ee71-8d31-4a75-a276-ea35ea70e45f.png">


# Update via declarative way
<img width="1190" alt="image" src="https://user-images.githubusercontent.com/75510135/126984032-709fe9e3-0630-4d02-a427-a2cd4b71e290.png">
- change the image name 
<img width="883" alt="image" src="https://user-images.githubusercontent.com/75510135/126985622-bd0602b2-b968-44b7-b343-fcf6440af08a.png">
- kubectl apply to update the existing pod

<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/126985846-2f268d3e-d5c0-4ffb-9c96-8f3b961749f7.png">
- check the logs using , kubectl get pods pod-name

<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/126985898-51b908b9-18d5-426a-933b-1746b1893c3e.png">

# Create deployment 
<img width="883" alt="image" src="https://user-images.githubusercontent.com/75510135/126988296-d6f3e373-918c-4f47-92a8-cad98bbe79d4.png">

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: client-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: client
        image: stephengrider/multi-container
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 3000

        
```
<img width="808" alt="image" src="https://user-images.githubusercontent.com/75510135/126992402-e35e53a0-3f54-49e9-b101-45e2b9db2666.png">

# Docker Desktop's Kubernetes Dashboard

updated 3-10-2021

This note is for students using Docker Desktop's built-in Kubernetes. If you are using Minikube, the setup here does not apply to you and can be skipped.

If you are using Docker Desktop's built-in Kubernetes, setting up the admin dashboard is going to take a little more work.

1. Grab the most current script from the install instructions:

https://github.com/kubernetes/dashboard#install

eg:

As of today, the kubectl apply command looks like this:

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml

Copy the URL within the apply command:

https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml

2. We will need to download the config file locally so we can edit it (make sure you are copying the most current URL from the official Github repo - do not rely on the version shown in the examples below).

If on Mac or using GitBash on Windows enter the following:

curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml > kubernetes-dashboard.yaml

If using PowerShell:

Invoke-RestMethod -Uri https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml -Outfile kubernetes-dashboard.yaml

3. Open up the downloaded file in your code editor and use CMD+F or CTL+F to find the args. Add the following two lines underneath --auto-generate-certificates:

    args:
      - --auto-generate-certificates
      - --enable-skip-login
      - --disable-settings-authorizer

4. Run the following command inside the directory where you downloaded the dashboard manifest file a few steps ago:

kubectl apply -f kubernetes-dashboard.yaml

5. Start the server by running the following command:

kubectl proxy

6. You can now access the dashboard by visiting:

http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/

7. You will be presented with a login screen:

8. Click the "SKIP" link next to the SIGN IN button.

9. You should now be redirected to the Kubernetes Dashboard:

Important! The only reason we are bypassing RBAC Authorization to access the Kubernetes Dashboard is that we are running our cluster locally. You would never do this on a public-facing server like Digital Ocean and would need to refer to the official docs to get the dashboard setup.

If you wish to instead create a sample user, you can follow the instructions here:

https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md
